{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Task: Predict Rainfall in Australia\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "Algorithm: Random Forest Classifier\n",
    "\n",
    "How to Run:\n",
    "\n"
   ],
   "metadata": {
    "id": "7PXRafR-5O_l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np #importing numpy with name np\n",
    "import pandas as pd #importing pandas with name pd"
   ],
   "metadata": {
    "id": "n-MQ3V78izW4"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Drop unused columns and columns and rows containing 'NA'\n",
    "\n",
    "df = pd.read_csv(\"/content/weatherAUS.csv\") #assigning data to the csv file\n",
    "df.drop(['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am'], inplace=True, axis=1) #dropping columns that contain all NA\n",
    "df = df.replace('NA', np.nan).dropna() #dropping any row that contains an NA in one of its elements\n",
    "df.columns"
   ],
   "metadata": {
    "id": "ifXKV1O3iz2I"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Reformat Date column from 'yyyy-mm-dd' to 'mm-dd'\n",
    "\n",
    "for date in df['Date']:\n",
    "  date = date[5:]\n",
    "\n",
    "  # if len(date) != 5:\n",
    "  #   raise Exception(\"Date not acceptable\")\n"
   ],
   "metadata": {
    "id": "pZoCMNyol5Ql"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# convert all text in data to numeric value\n",
    "\n",
    "text_columns = df.select_dtypes(include=[object]).columns\n",
    "print('text_columns: ', text_columns)\n",
    "\n",
    "for col in text_columns:\n",
    "  unique_vals = df[col].unique()\n",
    "  num = 0\n",
    "  for val in unique_vals:\n",
    "    df[col].replace(val, num, inplace=True)\n",
    "    num += 1\n",
    "\n",
    "# Save preprocessed data to new csv\n",
    "df.to_csv('/content/weatherAUSProcessed.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "id": "72AGogy5kK0H"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# print name of data type of each column to verify numeric values\n",
    "\n",
    "for col in df.columns:\n",
    "  print('column name: \\t', col)\n",
    "  print('data type: \\t', df[col].dtypes)\n",
    "  print('\\n')"
   ],
   "metadata": {
    "id": "N2reDkLR2f-c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train:test split of 80:20\n",
    "# random_state ensures consistent split on each instance\n",
    "# stratify forces equal representation of \"yes\" and \"no\" in y columns\n",
    "\n",
    "# Without stratification\n",
    "normal_split = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "print(\"Normal X_train.shape:\\t\\t\", normal_split[0].shape, \"\\nNormal X_test.shape:\\t\\t\", normal_split[1].shape)\n",
    "\n",
    "\n",
    "# With stratification\n",
    "stratified_split = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "\n",
    "print(\"\\nStratified X_train.shape:\\t\", stratified_split[0].shape, \"\\nStratified X_test.shape:\\t\", stratified_split[1].shape)\n",
    "\n",
    "y_counts = y.value_counts()\n",
    "norm_counts = normal_split[3].value_counts()\n",
    "strat_counts = stratified_split[3].value_counts()\n",
    "print(f\"\\ny counts: \\n{y_counts} \\nNo:Yes ratio: \\n{y_counts[1]/sum(y_counts)}\")\n",
    "print(f\"\\nnormal_split counts: \\n{norm_counts} \\nNo:Yes ratio: \\n{norm_counts[1]/sum(norm_counts)}\")\n",
    "print(f\"\\nstratified_split counts: \\n{strat_counts} \\nNo:Yes ratio: \\n{strat_counts[1]/sum(strat_counts)}\")"
   ],
   "metadata": {
    "id": "SVEn5Y3d4O0d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature Scaling Not Needed\n",
    "\n",
    "It's noticeable that most columns have unnormalized data. Though, this shouldn't be a problem for a randrom forest.\n",
    "\n",
    "\"CART, Random Forests, Gradient Boosted Decision Trees. These algorithms utilize rules (series of inequalities) and do not require normalization.\"\n",
    "-- https://towardsdatascience.com/all-about-feature-scaling-bcc0ad75cb35"
   ],
   "metadata": {
    "id": "_-fvtGQ7AvkH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest Classifier Design:\n",
    "\n",
    "Random Forests are designed to work with tabular data. Feature scaling is not necessary for an RF model. "
   ],
   "metadata": {
    "id": "mP3tyalCfdpt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# A few things to make testing and comparing designs easy\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "\n",
    "class RFC_model:\n",
    "  def __init__(self, name, model):\n",
    "    self.name = name\n",
    "    self.model = model\n",
    "    self.trained_model = None\n",
    "    self.y_pred = None\n",
    "    self.y_test = None\n",
    "    self.metrics = {\"Accuracy\": None,\n",
    "                   \"Precision\": None,\n",
    "                   \"F1\": None,\n",
    "                   \"Recall\": None,\n",
    "                   \"Confusion\": None}\n",
    "\n",
    "\n",
    "  def train_test_model(self, X_train, X_test, y_train):\n",
    "    self.trained_model = self.model.fit(X_train, y_train)\n",
    "    self.y_pred = self.model.predict(X_test)\n",
    "\n",
    "    return self.y_pred\n",
    "\n",
    "\n",
    "  def score_model(self, y_test):\n",
    "    if self.y_pred is None: return\n",
    "\n",
    "    y1 = y_test\n",
    "    y2 = self.y_pred\n",
    "    self.metrics.update({\"Accuracy\": accuracy_score(y1, y2),\n",
    "              \"Precision\": precision_score(y1, y2),\n",
    "              \"F1\": f1_score(y1, y2),\n",
    "              \"Recall\": recall_score(y1, y2),\n",
    "              \"Confusion\": confusion_matrix(y1, y2)})\n",
    "    \n",
    "    return self.metrics\n",
    "\n",
    "\n",
    "  def get_all(self):\n",
    "    contents = (self.name, self.model, self.trained_model, \n",
    "                self.y_pred, self.y_test, self.metrics)\n",
    "    return contents"
   ],
   "metadata": {
    "id": "TfeSqycxKWzP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a few versions of a Random Forest\n",
    "# Two sets: one for each type of data split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "number_of_trees = [2, 5, 10, 20, 50, 100, 150, 200, 250]\n",
    "models = []\n",
    "\n",
    "for i, n in enumerate(number_of_trees):\n",
    "  model = RandomForestClassifier(n_estimators=n, max_depth=3, random_state=0)\n",
    "  models.append(RFC_model(f\"model{i}\" , model))\n",
    "  print(f\"model{i}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = stratified_split\n",
    "\n",
    "print(\"Stratified Split: \")\n",
    "for model in models:\n",
    "  model.train_test_model(X_train, X_test, y_train)\n",
    "  model.score_model(y_test)\n",
    "  print(model.metrics)\n",
    "# for model in models:\n",
    "#   y_pred = train_test_model(model, X_train, y_train, X_test)\n",
    "#   scores = score_model(y_test, y_pred)\n",
    "# print_scores(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}